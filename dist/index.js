import { LRParser } from '@lezer/lr';

// This file was generated by lezer-generator. You probably shouldn't edit it.
const parser = LRParser.deserialize({
  version: 14,
  states: "$tO`QPOOOwQPO'#C`O!PQPO'#CcOOQO'#C_'#C_OOQO'#C^'#C^QOQPOOO!WQPO'#CbO!]QPO'#CaOOQO'#Ce'#CeO!hQPO,58zOOQO,58z,58zO!pQPO'#CdOOQO'#Cg'#CgO#_QPO,58}OOQO,58},58}O`QPO,58|O#fQPO'#CfO#kQPO,58{OOQO-E6c-E6cOOQO1G.f1G.fO`QPO'#ChO#vQPO,59OOOQO-E6e-E6eOOQO1G.i1G.iOOQO1G.h1G.hOOQO,59Q,59QOOQO-E6d-E6dOOQO,59S,59SOOQO-E6f-E6f",
  stateData: "$e~O_OS`OSaOSbOS~OcPOdROhQOjROkROlROmRO~OdUOgYO~Oi^O~P`Oe_O~Of`OdTXgTX~OdUOgcO~OfdOcWXdWXhWXiWXjWXkWXlWXmWX~OigO~P`OdUO~Of`OdTagTa~OfdOcWadWahWaiWajWakWalWamWa~O",
  goto: "!r]PP^kry}r!U!Y!`!f!lQTOSZQ]Qh_RkdZSOQ]_dZROQ]_dTWPXSVPXRi`T[Q]QXPRbXQaVRjaQ]QRf]QeZRle",
  nodeNames: "âš  JSON Element Value Object Members Member Array Elements",
  maxTerm: 29,
  skippedNodes: [0],
  repeatNodeCount: 4,
  tokenData: "'j~RaXY!WYZ!]]^!bpq!grs!l{|$Y|}%]}!O$Y!Q![$`![!]%b!}#O%g#P#Q%l#Y#Z%q#b#c&`#h#i&w#o#p'`#q#r'e~!]O`~~!bOa~~!gOb~~!lO_~~!oVOr!lrs#Us#O!l#O#P#Z#P;'S!l;'S;=`$S<%lO!l~#ZOd~~#^RO;'S!l;'S;=`#g;=`O!l~#jWOr!lrs#Us#O!l#O#P#Z#P;'S!l;'S;=`$S;=`<%l!l<%lO!l~$VP;=`<%l!l~$]P!Q![$`~$eSj~!O!P$q!Q![$`!g!h%P#X#Y%P~$tP!Q![$w~$|Pj~!Q![$w~%SR{|$q}!O$q!Q![$w~%bOf~~%gOe~~%lOh~~%qOi~~%tP#T#U%w~%zP#`#a%}~&QP#g#h&T~&WP#X#Y&Z~&`Ol~~&cP#i#j&f~&iP#`#a&l~&oP#`#a&r~&wOm~~&zP#f#g&}~'QP#i#j'T~'WP#X#Y'Z~'`Ok~~'eOc~~'jOg~",
  tokenizers: [0],
  topRules: {"JSON":[0,1]},
  tokenPrec: 0
});

export { parser };
